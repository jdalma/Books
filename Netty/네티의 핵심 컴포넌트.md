
네티의 비동기 프로그래밍 모델은 Future와 콜백의 개념, 그리고 더 깊은 단계에서 이벤트를 핸들러 메서드로 발송하는 작업을 기반으로 작동한다.  
작업을 가로채고 인바운드나 아웃바운드 데이터를 즉시 변환하려면 콜백을 제공하거나 작업이 반환하는 Future를 활용하면 간단하다.  
  
네티는 이벤트를 발생시켜 Selector를 애플리케이션 밖으로 추상화하므로 개발자가 발송 코드를 직접 작성할 필요가 없다.
각 Channel에 할당되는 EventLoop는 내부적으로 다음을 비롯한 모든 이벤트를 처리한다.

1. 관심 이벤트 등록
2. 이벤트를 ChannelHandler로 발송
3. 추가 동작 스케줄링

EventLoop 자체는 한 Channel의 모든 입출력 이벤트를 처리하는 한 스레드에 의해 제어되며, EventLoop의 수명 기간 동안 달라지지 않는다.

# 네티가 제공하는 전송 종류

![](./imgs/nettyTransKind.png)

<h3>NIO: 논블로킹 입출력</h3>

모든 입출력 작업의 완전한 비동기 구현을 제공하며, NIO 하위 시스템이 도입된 이후 사용할 수 있게 된 셀렉터 기반 API를 활용한다.  

1. 새로운 Channel 수락되고 준비됨
2. Channel 연결이 완료됨
3. Channel에 읽을 데이터가 있음
4. Channel을 이용해 데이터를 기록할 수 있음

애플리케이션이 상태 변경에 반응한 후에는 셀렉터가 재설정되며 해당 스레드에서 변경을 검사하고 적절하게 반응하는 프로세스가 반복된다.  

![](./imgs/nettyNio.png)

위와 같은 내부 사항은 네티의 모든 전송 구현에 공통적인 사용자 수준 API에 의해 숨겨진다.  

<h3>Epoll: 리눅스용 네이티브 논블로킹 전송</h3>

네티의 NIO 전송은 자바가 제공하는 비동기/논블로킹 네트워크의 공통 추상화에 기반을 둔다.  
덕분에 네티의 논블로킹 API를 모든 플랫폼에서 이용할 수 있지만 JDK는 모든 시스템에서 동일한 기능을 제공하기 위해 기능을 절충해야 하므로 어느 정도 제약을 감수해야 한다는 뜻이기도 하다.  
  
리눅스의 중요성이 높아지면서 우수한 입출력 이벤트 알림 기능인 `epoll`을 비롯한 다양한 고급 기능이 개발됐다.  
**epoll은 기존의 POSIX select 및 poll 시스템 호출에 비해 높은 성능을 제공하는 API로서, 리눅스 커널 2.5.44버전에 도입됐고, 이후 리눅스의 논블로킹 네트워킹에서 사실상의 표준으로 자리 잡았다.**  
리눅스 JDK NIO API는 이러한 epoll 호출을 이용한다.  
  
네티는 적은 부담으로 인터럽트를 수행하며, 자체 설계와 더 일관되게 epoll을 이용하는 리눅스용 NIO API를 제공한다.  
고부하 조건에서 JDK의 NIO구현보다 훨씬 우수한 성능을 보이는 것을 확인할 수 있다.  
(JDK구현은 레벨 트리거 방식인 데 반해, 네티는 에지 트리거 방식이다.)  
  
NIO대신 epoll을 이용하도록 바꾸려면
- NioEventLoopGroup을 EpollEventLoopGroup으로 변경
- NioServerSocketChannel을 EpollServerSocketChannel로 변경
  
> **제로 카피** [Efficient data transfer through zero copy](https://developer.ibm.com/articles/j-zerocopy/)  
> NIO와 Epoll 전송에서만 이용 가능한 기능으로서, **파일 시스템의 데이터를 커널 공간에서 사용자 공간으로 복사하는 과정을 생략해 빠르고 효과적으로 네트워크로 이동할 수 있게 해준다.**  
> 데이터 암호화나 압축을 구현하는 파일 시스템에서는 이용할 수 없고 파일의 원시 콘텐츠만 전송할 수 있다.

<h3>OIO: 기존 블로킹 입출력</h3>

이 전송 구현은 절충이 필요한 상황을 위한 것으로서 `java.net`의 블로킹 구현에 기반을 두므로 비동기 방식은 아니지만 특수한 용도에 아주 적합하다.  
예를 들어, JDBC와 같은 블로킹 호출 방식의 라이브러리가 이용된 레거시의 경우 네티의 OIO 전송을 이용하고 나중에 순수 비동기 전송 중 하나로 코드를 이식할 수 있다.  
  
수신하는 ServerSocket으로 도착하는 새로운 연결을 한 스레드가 수락하며, 피어와 상호작용할 새로운 소켓을 만들고 트래픽을 제어할 새로운 스레드를 할당한다.  
네티가 비동기 전송에 이용돠는 것과 동일한 API로 OIO를 사용하고 싶다면 **입출력 작업이 완료되기를 기다리는 시간(밀리초)을 지정하는 `SO_TIMEOUTSocket` 플래그를 사용할 수 있다.**  
지정한 시간 내에 작업을 완료하지 못하면 SocketTimeoutException이 발생하며, 네티는 이 예외를 포착하고 처리 루프를 계속 진행하며, 다음 EventLoop를 실행할 때 다시 시도한다.  
이것이 네티와 같은 비동기 프레임워크에서 OIO를 지원하는 유일한 방법이다.  

![](./imgs/oio.png)

<h3>JVM 내부 통신용 로컬 전송</h3>

네티는 동일한 JVM 내에서 실행되는 클라이언트와 서버 간 비동기 통신을 위한 로컬 전송을 제공한다.  
이 전송에서 서버 Channel과 연결되는 SocketAddress는 실제 네트워크 주소에 바인딩되지 않고 서버가 실행되는 동안 레지스트리에 저장되며, Channel이 닫히면 레지스트리에서 등록히 해제된다.  
이 전송은 실제 네트워크 트래픽을 수신하지는 않으므로 다른 전송 구현과 상호운용 할 수 있다.  


# 이벤트와 핸들러

네티는 작업 상태의 변화를 알리기 위해 고유한 이벤트를 이용하며, 발생한 이벤트를 기준으로 적절한 동작을 트리거할 수 있다.  
다음과 같은 동작이 포함된다.  

1. 로깅
2. 데이터 변환
3. 흐름 제어
4. 애플리케이션 논리

네티는 네트워크 프레임워크이므로 이벤트 역시 인바운드 또는 아웃바운드 데이터 흐름에 대한 연관성을 기준으로 분류된다.  

1. **인바운드 이벤트**
   1. 연결 활성화 또는 비활성화
   2. 데이터 읽기
   3. 사용자 이벤트
   4. 오류 이벤트
2. **아웃바운드 이벤트**
   1. 원격 피어로 연결 열기 또는 닫기
   2. 소켓으로 데이터 쓰기 또는 플러시

![](./imgs/inoutBound.png)

위의 이미지는 이벤트 핸들러의 체인을 통해 이벤트가 처리되는 방법을 표현한다.  
네티의 `ChannelHandler`는 위의 핸들러와 같이 핸들러의 기본 추상화를 제공한다.  
**지금은 각 핸들러 인스턴스가 특정 이벤트에 반응해 실행되는 일종의 콜백이라고 이해하자.**  
  
**모든 이벤트는 핸들러 클래스의 사용자 구현 메서드로 전달할 수 있으며, 이것은 이벤트 기반 패러다임이 직접적으로 애플리케이션 구성 요소로 변환되는 좋은 사례다.**  
네티는 HTTP 및 SSL/TLS와 같은 프로토콜용 핸들러를 비롯해 곧바로 이용할 수 있는 미리 정의된 핸들러를 광범위하게 제공한다.  

# 데이터의 흐름을 관리하고 애플리케이션의 처리 논리를 실행하는 컴포넌트
  
네티가 제공하는 광범위한 기능은 소수의 인터페이스에 의존한다.  
이 의미는 코드 기반을 전면적으로 리팩터링하지 않고도 애플리케이션 논리를 전면적으로 수정할 수 있다는 의미이다.  

## Channel 인터페이스

Channel은 자바 NIO의 기본 구조이며, 다음과 같이 정의된다.

> 하나 이상의 입출력 작업(읽기 또는 쓰기)을 수행할 수 있는 하드웨어 장치, 파일, 네트워크 소켓, 프로그램 컴포넌트와 같은 엔티티에 대한 열린 연결

일단 Channel을 들어오는(`인바운드`) 데이터와 나가는(`아웃바운드`) 데이터를 위한 **운송 수단** 이라고 볼 수 있다.  
Channel을 열거나 닫고, 연결하거나 끊을 수 있으며, 자바 기반 네트워크에서 기본 구조는 Socket 클래스다.  
기본 입출력 작업(`bind()`, `connect()`, `read()`, `write()`)은 기본 네트워크 전송에서 제공하는 기본형을 이용한다.  
  
**네티의 Channel 인터페이스는 Socket으로 직접 작업할 때의 복잡성을 크게 완화하는 API를 제공하며 다수의 미리 정의된 특수한 구현을 포함하는 광범위한 클래스 계층의 루트다.**  

1. EmbeddedChannel
2. LocalServerChannel
3. NioDatagramChannel
4. NioSctpChannel
5. NioSocketChannel
6. ...

Channel 인터페이스는 모든 입출력 작업에 사용되므로 전송 API의 핵심이라고 할 수 있다.  

![](./imgs/channelInterfaceLayer.png)

Channel에 ChannelPipeline과 ChannelConfig가 할당되기에 **특정한 전송에 고유 설정이 필요할 때는 ChannelConfig의 하위 형식을 구현할 수도 있다.**  
Channel은 **고유하므로** 정렬 순서를 보장하기 위해 Comparable 인터페이스를 하위 인터페이스로 지정하였다.  
  
**Netty의 Channel 구현은 스레드에 대해 안전하므로 여러 스레드를 이용하는 경우에도 Channel의 참조를 저장하고 원격 피어에 뭔가를 출력할 때 이용할 수도 있다.**  

```java
public static void writingToChannel() {
    Channel channel = null;

    // 기록할 데이터를 포함하는 ByteBuf를 생성
    ByteBuf buf = Unpooled.copiedBuffer("your data", CharsetUtil.UTF_8);
    ChannelFuture cf = channel.writeAndFlush(buf);

    // 기록이 완료되면 알림을 받을 ChannelFutureListener를 추가
    cf.addListener((ChannelFutureListener) future -> {
        if (future.isSuccess()) {
            System.out.println("Write successful");
        } else {
            System.err.println("Write error");
            future.cause().printStackTrace();
        }
    });
}

public static void writingToChannelManyThreads() {
    final Channel channel = null;
    final ByteBuf buf = Unpooled.copiedBuffer("your data", CharsetUtil.UTF_8);
    Runnable writer = () -> channel.write(buf.duplicate());
    Executor executor = Executors.newCachedThreadPool();

    // write in one thread
    executor.execute(writer);

    // write in another thread
    executor.execute(writer);
}
```

## ChannelPipeline 인터페이스

ChannelPipeline은 ChannelHandler 체인을 위한 컨테이너를 제공하며, 체인 상에서 인바운드와 아웃바운드 이벤트를 전파하는 API를 정의한다.  
**Channel이 생성되면 여기에 자동으로 자체적인 ChannelPipeline이 할당된다.**  

1. ChannelInitializer 구현은 ServerBootstrap에 등록된다.
2. ChannelInitializer.initChannel()이 호출되면 ChannelInitializer가 ChannelHandler의 커스텀 집합을 파이프라인에 설치한다.
3. ChannelInitializer는 ChannelPipeline에서 자신을 제거한다.

ChannelHandler는 광범위한 용도를 지원할 수 있게 특별히 설계됐으며, **ChannelPipeline을 통해 오가는 이벤트(데이터 포함)를 처리하는 모든 코드를 위한 범용 컨테이너라고 할 수 있다.**  

> **가로채기 필터(intercepting filter)** 라는 공통 설계 패턴을 구현하며, 이 패턴에서는 여러 명령이 체인으로 연결되고 한 명령의 출력이 다음 명령의 입력이 된다.  
> 대표적인 예로 유닉스 파이프가 있다.  
  
파이프라인을 통해 이벤트를 이동하는 역할은 애플리케이션의 부트스트랩 단계나 초기화 중에 설치된 ChannelHandler가 담당한다.  
이들 객체는 **이벤트를 수신하고, 구현된 처리 논리를 실행하며, 체인 상의 다음 핸들러로 데이터를 전달한다.**  
실행되는 순서는 추가된 순서에 의해 결정되며, ChannelPipeline이라고 말할 때는 이러한 ChannelHandler의 정렬된 배치 전체를 의미한다고 보면 된다.  

![](./imgs/channelPipeline.png)

그림에 Socket으로 나오는 네트워크 전송에 도달하면 보통 이때 쓰기 작업이 트리거 된다.  
**네티에서 메세지를 보내는 데는 Channel에 직접 기록하거나 ChannelHandler와 연결된 ChannelHandlerContext에 기록하는 두 가지 방법이 있다.**  
전자의 방법은 메시지가 ChannelPipeline의 뒤쪽에서 시작되며, 후자의 방법은 메시지가 ChannelPipeline의 다음 핸들러에서 시작된다.  
  
> 인바운드와 아웃바운드 핸들러에서 각 메서드에 인수로 제공되는 ChannelHandlerContext를 이용해 이벤트를 현재 체인의 다음 핸들러로 전달할 수 있다.  
> 네티는 ChannelHandlerContext를 통해 다음 핸들러를 전달하는 구현체 ChannelInboundHandlerAdapter와 ChannelOutboundHandlerAdpater를 제공한다.
  
네티는 애플리케이션의 처리 논리를 쉽게 개발할 수 있게 어댑터 클래스 형태로 여러 기본 핸들러의 구현을 제공한다.  
**파이프라인의 각 ChannelHandler는 이벤트를 체인의 다음 핸들러로 전달해야 하는데, 이러한 어댑터 클래스(및 해당 상위 클래스)는 이 작업을 자동으로 해주므로 특수한 동작이 필요한 메서드와 이벤트만 재정의할 수 있다.**  

## ChannelHandler 인터페이스

개발자의 관점에서 네티의 핵심 컴포넌트는 **인바운드와 아웃바운드의 데이터 처리에 적용되는 모든 애플리케이션 논리의 컨테이너 역할을 하고 네트워크 이벤트에 의해 트리거 되는 `ChannelHandler`다.  
**데이터를 다른 포맷으로 변환하거나 작업 중 발생한 예외를 처리하는 등 거의 모든 종류의 작업에 활용할 수 있다.**  
  
1. 데이터를 한 포맷에서 다른 포맷으로 변환
2. 예외에 대한 알림 제공
3. Channel의 활성화 또는 비활성화에 대한 알림 제공
4. Channel을 EventLoop에 등록할 때 또는 등록 해제할 때 알림 제공
5. 사용자 정의 이벤트에 대한 알림 제공

## EventLoop 인터페이스

**연결의 수명주기 중 발생하는 이벤트를 처리하는 네티의 핵심 추상화를 정의한다.**  

![](./imgs/eventLoopStructure.png)

1. 한 개의 EventLoopGroup은 하나 이상의 EventLoop를 포함한다.
2. 한 개의 EventLoop는 수명주기 동안 한 Thread로 바인딩된다.
3. 한 개의 EventLoop에서 처리되는 모든 입출력 이벤트는 해당 전용 Thread에서 처리된다.
4. 한 개의 Channel은 수명주기 동안 한 EventLoop에 등록할 수 있다.
5. 한 개의 EventLoop를 하나 이상의 Channel로 할당할 수 있다.
   1. 즉, 각 Channel은 한 개의 EventLoop에 등록될 수 있으며 EventLoop는 여러 개의 Channel을 가질 수 있다.

> **이 설계에서는 한 Channel의 입출력이 동일한 Thread에서 처리되므로 동기화가 사실상 필요 없다.**

## ChannelFuture 인터페이스

네티의 모든 입출력 작업은 비동기적이다. 작업이 즉시 반환되지 않을 수 있으므로 나중에 결과를 확인하기 위해 네티는 `ChannelFuture`를 제공한다.  
  
이 인터페이스의 `addListener()`는 작업이 완료되면(성공 여부와 관계없이) 알림을 받을 **ChannelFutureListener** 하나를 등록한다.  
작업이 실행되는 시점은 여러 요소에 의해 좌우되지만 실행된다는 점은 확실하다. **또한 동일한 Channel에 속하는 모든 작업은 호출된 순서와 동일한 순서로 실행된다.**  

## 인코더와 디코더

네트워크 데이터는 반드시 연속된 바이트여야 하기에, 네티로 메시지를 전송하거나 수신할 때는 데이터를 변환하는 과정을 거친다.  
인바운드 메시지는 바이트에서 다른 포맷(보통은 자바 객체)으로 변환되는 디코딩을 가지며, 아웃바운드 메시지는 반대로 바이트로 인코딩된다.  
  
원하는 기능에 따라 이용할 수 있는 다양한 인코더와 디코더의 추상 클래스가 제공된다.  
다른 핸들러로 인코더와 디코더의 역할을 할 수도 있지만, ChannelHandler를 쉽게 만들 수 있게 Adapter 클래스가 있는 것처럼, **네티가 제공하는 모든 인코더/디코더 어댑터 클래스는 ChannelInboundHandler나 ChannelOutboundHandler를 구현한다.**  
  
인바운드 데이터의 경우 Channel에서 읽는 각 메시지에 대해 호출되는 `channelRead()` 메서드/이벤트를 재정의한다.  
이 메서드는 제공된 디코더의 `decode()` 메서드를 호출한 후 디코딩된 바이트를 파이프라인의 다음 ChannelInboundHandler로 전달한다.  
아웃바운드 메시지를 위한 패턴은 반대이며, 인코더가 메시지를 바이트로 변환한 후 다음 ChannelOutboundHandler로 전달한다.  

## SimpleChannelInboundHandler 추상 클래스

디코딩된 메시지를 수신하고 데이터에 비즈니스 논리를 적용하는 핸들러를 많이 필요로 하는데, 이러한 ChannelHandler를 만들려면 기본 클래스인 **SimpleChannelInboundHandler<T>** 를 확장하면 된다.  
여기서 `T`는 처리하려믄 메시지의 자바 형식이며, `channelRead0()`이 가장 중요하다.  
직접 커스텀하여 구현할 수 있지만, **현재 입출력 스레드를 블로킹하지 않아야 한다는 요건이 있다.**  

# 부트스트랩

네티의 부트스트랩 클래스는 **프로세스를 지정된 포트로 바인딩하거나 프로세스를 지정된 호스트의 저징된 포트에서 실행 중인 다른 호스트로 연결하는 등의 일을 하는 애플리케이션의 네트워크 레이어를 구성한다.**  
따라서 부트스트랩에는 클라이언트용(Bootstrap)과 서버용(ServerBootstrap)의 두 가지 유형이 있다.  
  
서버는 연결 요청을 수신해야 하므로 로컬 포트로 바인딩하는 ServerBootstrap을 이용하지만 클라이언트는 원격 호스트와 포트로 연결해야 하므로 Bootstrap을 이용한다.  
더 중요한 차이점은 **ServerBootstrap은 EventLoopGroup이 두 개 필요하다는 것이다.**  
  
서버는 각기 다른 Channel의 두 집합을 필요로 한다.  
첫 번째 집합은 로컬 포트로 바인딩된 서버 자체의 수신 소켓을 나타내는 ServerChannel 하나를 포함한다.  
두 번째 집합은 서버가 수락한 연결마다 하나씩 들어오는 클라이언트 연결을 처리하기 위해 생성된 모든 Channel을 포함한다.  

![](./imgs/serverBootstrap.png)

ServerChannel과 연결된 EventLoopGroup은 들어오는 연결 요청에 대해 Channel을 생성하는 역할을 EventLoop 하나에 할당한다.  
연결이 수락되면 두 번째 EventLoopGroup이 해당 Channel에 EventLoop를 할당한다.  

# 콜백

다른 메서드로 자신에 대한 참조를 제공할 수 있는 메서드다. 다른 메서드에서는 이 참조가 가리키는 메서드를 필요할 때 호출할 수 있다.  
(관심 대상에게 작업 완료를 알리는 가장 일반적인 방법 중 하나다.)  
  
네티는 이벤트를 처리할 때 내부적으로 콜백을 이용한다.  
콜백이 트리거되면 [ChannelHandler 인터페이스](https://netty.io/4.1/api/io/netty/channel/ChannelHandler.html)의 구현을 통해 이벤트를 처리할 수 있다.  
예를 들어, 아래와 같이 새로운 연결이 이뤄지면 ChannelHandler 콜백인 channelActive가 호출된다.  

```java
public class ChannelHandler extends ChannelInboundHandlerAdapter {

    // 새로운 연결이 이뤄지면 해당 메서드가 호출된다.
    @Override
    public void channelActive(ChannelHandlerContext ctx) throws Exception {
        System.out.println("Client " + ctx.channel().remoteAddress() + " connected");
        super.channelActive(ctx);
    }
}
```

# Future

작업이 완료되면 이를 애플리케이션에 알리는 한 방법으로 사용되며, 이 객체는 비동기 작업의 결과를 담는 자리표시자 역항를 하며, 미래의 어떤 시점에 작업이 완료되면 그 결과에 접근할 수 있게 해준다.  
  
JDK는 `java.util.concurrent.Future` 인터페이스를 제공하지만, 제공되는 구현에는 수동으로 작업 완료 여부를 확인하거나 완료되기 전까지 블로킹하는 기능만 있다.  
**그래서 네티는 비동기 작업이 실행됐을 때 이용할 수 있는 자체 구현 [ChannelFuture](https://netty.io/4.0/api/io/netty/channel/ChannelFuture.html)를 제공한다.**  
  
ChannelFuture에는 ChannelFutureListener 인스턴스를 하나 이상 등록할 수 있는 추가 메서드가 있다.  
작업이 완료되면 리스너의 콜백 메서드인 `operationComplete()`가 호출되며, 이 시점에 리스너는 작업이 정상적으로 완료됐는지, 아니면 오류가 발생했는지 확인할 수 있다.  
  
네티의 모든 아웃바운드 입출력 작업은 ChannelFuture를 반환하며 진행을 블로킹하는 작업은 없다.  
**네티는 기본적으로 비동기식이며 이벤트 기반이다.**  

```java
ChannelFutureListener callback = (ChannelFutureListener) future -> {
    if (future.isSuccess()) {
        // 3. 작업이 성공적인 경우 데이터를 저장할 ByteBuf를 생성
        ByteBuf buffer = Unpooled.copiedBuffer("Hello", Charset.defaultCharset());

        // 4. 데이터를 비동기식으로 원격 피어로 전송하고 ChannelFuture를 반환
        ChannelFuture wf = future.channel().writeAndFlush(buffer);
        // ...
    } else {
        // 3. 작업이 성공적이지 않다면 Future에서 예외를 꺼낸다.
        Throwable cause = future.cause();
        cause.printStackTrace();
    }
};

System.out.println("Client " + ctx.channel().remoteAddress() + " connected");

Channel channel = null;

// 1. 원격 피어로 비동기 연결을 만듦
ChannelFuture future = channel.connect(new InetSocketAddress("192.68.0.01", 25));

// 2. 작업이 완료되면 알림을 받음
future.addListener(callback);
```

콜백과 Future는 상호 보완적 메커니즘이며 둘의 조합을 통해 네티의 핵심 구성요소 중 하나를 형성한다.  
