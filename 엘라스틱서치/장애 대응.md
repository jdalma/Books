
# 모니터링

<h3>메트릭비트</h3>

**매트릭비트** 는 여러 서비스의 메트릭 데이터를 주기적으로 수집해 엘라스틱서치나 로그스태시, 카프카 등으로 넘기는 서비스다.  
다양한 시스템에서 수집해야 할 주요 지표 데이터를 모듈이라는 패키지로 미리 묶어 제공한다.  
  
여러 개의 메트릭비트 인스턴스가 각각 노드 범위에서 데이터를 수집하도록 설정할 수 있지만 공식 문서는 **한 개의 메트릭비트 인스턴스가 클러스터 범위에서 데이터를 수집하는 방법을 권장한다.**  
모든 엘라스틱서치 노드에 메트릭비트를 설치하여 사용하면 많은 지표 데이터를 마스터 노드에서 수집하기 때문에 클러스터 단위로 사용하는 것이 좋다.  
  
- 메트릭 비트의 scope 설정을 `cluster` 또는 `node`로 지정할 수 있다.
- 키바나의 얼럿 기능을 사용하려면 노드의 역할에 `remote_cluster_client`를 추가해야 한다.
- 얼럿 기능을 사용하려면 모든 통신을 TLS로 구성해야 한다.
- 한 개의 메트릭비트 `output.elasticsearch.hosts`에 여러 호스트를 등록하면 라운드 로빈으로 분산해서 이벤트를 넘긴다.
  
<h3>그라파나</h3>

매트릭비트는 특정 기능을 사용하기 위해서는 유료 구독이 필요하다. 대체 방안으로 그라파나가 있다.  
그라파나는 메트릭 데이터를 시각화하는 오픈소스 플랫폼으로, 많은 서비스에서 모니터링을 위한 대시보드와 알람 시스템으로 채택하고 있다.  
지표 데이터는 메트릭비트로 수집해 엘라스틱에 저장하고 그라파나에서 알람을 등록하는 방법이다.  

# 장애 대응

1. 모든 노드가 클러스터에 붙어 있는지, 미할당 샤드가 생겼는지 확인한다
2. `GET _cat/health`를 통해 클러스터의 red, yellow 상태 돌입 여부와 현재 클러스터에 합류된 것으로 판단되는 노드의 수를 확인한다.
3. `GET _cat/nodes`를 통헤 어떤 노드가 클러스터에서 빠졌는지 마스터 노드가 제대로 선출되어 있는지 파악한다.
4. `GET _nodes/stats` 평균 부하, 힙 사용량, 메모리 사용량, CPU 사용량, 디스크 사용량을 확인한다.

<h3>샤드 할당 비활성화</h3>

노드 하나가 클러스터에서 빠지면 그 노드가 들고 있던 샤드의 수만큼 복제본 샤드의 수도 줄어든다.  
장애 상황은 대부분 클러스터의 부하가 높은 상황이 많기 때문에 `number_of_replicas`를 맞추기 위해 새 복제본 샤드를 할당하고 데이터를 복사하는 작업은 부하를 더 줄 수밖에 없다.  
부하를 받은 노드는 다시 클러스터에서 빠지고 연쇄적인 장애를 일으킬 가능성이 있다.  
  
이런일을 막기 위해 샤드 할당을 비활성화해야 한다.  

<h3>클라이언트의 트래픽 차단</h3>

샤드 할당을 비활성화한 뒤에는 클러스터의 리소스를 장애 상황 복구에 집중할 수 있도록 클라이언트의 트래픽을 차단하는 것이 좋다.  
노드 재시작 등의 조치를 했다면 샤드 복구 과정이 이어진다.  
이 과정에 샤드에 변경이 있었다면 엘라스틱서치는 해당 작업을 전파해서 재처리하는 과정을 수행하기 때문에 추가 색인 작업을 차단하는 것도 중요하다.  
  
이럴 때를 위해 클러스터 구성 시 처음부터 조정 전용 노드를 앞에 두어 장애 발생 시 조정 전용 노드를 내려버려도 된다.  

<h3>샤드 복구 대기</h3>

만약 데이터 노드의 재기동을 수행했다면 미할당 샤드가 많이 생겼을 것이다.  
샤드 할당을 다시 all로 활성화하고 샤드 복구 작업도 부하가 큰 작업이라서 클러스터 상태가 green으로 돌아올 때 까지 대기해야 한다.  
  
만약 미할당 샤드가 남았는데 샤드 할당이 더 이상 진행되지 않는다면 `GET _cluster/allocation/explain?pretty`를 호출해서 원인을 파악할 수 있다.  
  
```
GET [인덱스 이름]/_recovery?human
GET _recovery?human
```

노드 하나가 네트워크를 통해 동시에 수행하는 샤드 복구 작업의 수는 기본은 2이지만 `cluster.routing.allocation.node_concurrent_recoveries` 설정으로 변경시킬 수 있다.  



# 댕글링 인덱스

클러스터에 노드가 합류할 때, 로컬 데이터 디렉터리에는 샤드 데이터가 있는데 클러스터의 메타 데이터에는 해당 인덱스와 샤드 정보가 없다면 엘라스틱서치는 이들을 **댕글링 인덱스** 와 샤드로 취급한다.  
특정 노드가 클러스터에서 제외된 이후 클러스터에서 많은 인덱스를 삭제했다고 가정했을 때, 그 뒤 해당 노드가 클러스터에 나중에 다시 합류하면 클러스터 메타데이터에는 더 이상 남아 있지 않은 인덱스인데 노드의 로컬에는 인덱스 데이터가 남아있다.  
이런 경우 로컬 샤드 데이터와 클러스터 메타데이터가 불일치하므로 댕글링 인덱스가 발생한다. 이런 상황에 발생한 댕글링 인덱스는 더 이상 인덱스를 유지할 필요가 없는 데이터이기 때문에 삭제해도 무방하다.  
  
하지만 만약 마스터 노드에 심각한 문제가 발생해서 메타데이터가 깨지고 각 노드의 로컬 데이터와 메타데이터가 맞지 않을 때에도 댕글링 인덱스가 생긴다.  
이런 경우는 상황이 심각해진다.  
  
> **인덱스 묘비**  
> 인덱스 삭제 작업은 빈번하게 일어날 수 있는 작업이고 노드의 롤링 리스타트도 흔히 수행하는 작업이다.  
> 노드 한 대가 잠시 재기동 되는 동안 인덱스가 하나 삭제됐다면 재기동 완료 이후 바로 댕글링 인덱스가 발생할 수 있지 않을까?  
> 이런 상황을 방지하기 위해 엘라스틱서치는 인덱스를 삭제할 때 마다 **인덱스 묘비** 를 세운다.  
>   
> 인덱스 묘비는 **특정 인덱스가 삭제됐다고 클러스터 상태에 명시적으로 남기는 기록이다.**  
> 엘라스틱서치는 댕글링 인덱스 판정을 내리기 전에 인덱스 묘비를 살펴보고 명시적으로 삭제된 인덱스라면 **댕글링 인덱스를 발생시키지 않는다.**  

<h3>댕글링 인덱스 탐지와 대응</h3>

ES 7.9 버전의 미만에서는 댕글링 인덱스가 확인되면 바로 일반 인덱스로 전환하여 데이터를 최대한 적재한다.  
7.9 버전부터는 댕글링 인덱스 자동 적재 기능은 비활성화되었고 댕글링 인덱스 API를 이용하여 직접 결정할 수 있다.  
- `GET _dangling` 댕글링 인덱스 조회
