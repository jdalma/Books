
# 인덱스 설정

인덱스 설정을 조회하려면 `GET [인덱스 이름]/_settings`로 조회할 수 있다.  
사전에 존재하지 않는 인덱스에 문서 색인을 요청하면 ES는 인덱스를 자동으로 생성한다.  

```json
// req
GET my_index/_settings

// res
{
  "my_index": {
    "settings": {
      "index": {
        "routing": {
          "allocation": {
            "include": {
              "_tier_preference": "data_content"
            }
          }
        },
        "number_of_shards": "1",
        "provided_name": "my_index",
        "creation_date": "1701589928336",
        "number_of_replicas": "1",
        "uuid": "D04h6TQ4TneP3YMujx8rHA",
        "version": {
          "created": "8040299"
        }
      }
    }
  }
}
```

## number_of_shards

이 인덱스가 데이터를 몇 개의 샤드로 쪼갤 것인지 지정하는 값이다.  
이 값은 한 번 지정하면 `reindex` 같은 동작을 통해 인덱스를 통째로 재색인하는 등 특별한 작업을 수행하지 않는 한 바꿀 수 없기 때문에 신중하게 설계해야 한다.  
  
샤드 개수를 어떻게 지정하느냐는 엘라스틱서치 클러스터 전체의 성능에도 큰 영향을 미친다.  
**샤드 하나마다 루씬 인덱스가 하나씩 더 생성된다는 사실과 주 샤드 하나당 복제본 샤드도 늘어난다.**  
  
클러스터에 샤드 숫자가 너무 많아지면 클러스터 성능이 떨어지며 특히 색인 성능이 감소한다.  
그러나 인덱스당 샤드 숫자를 적게 지정하면 샤드 하나의 크기가 커진다.  
샤드의 크기가 커지면 장애 상황 등에서 복구에 너무 많은 시간이 소요되고 특히 클러스터 안정성이 떨어진다.  
  
TODO(6.4 샤드 운영 전략)

## number_of_replicas

주 샤드 하나당 복제본 샤드를 몇 개 둘 것인지를 지정하는 설정이다.  
ES 클러스터에 몇 개의 노드를 붙일 것이며 어느 정도의 고가용성을 제공할 것인지 등을 고려해서 지정하면 된다.  
이 값은 인덱스 생성 후에도 동적으로 변경할 수 있다.  
  
값을 0으로 설정하여 복제본 샤드를 생성하지 않는 설정은 주로 대용량의 초기 데이터를 마이그레이션 하는 등의 시나리오에서 쓰기 성능을 일시적으로 끌어올리기 위해 사용한다.  

## refresh_interval

해당 인덱스를 대상으로 refresh를 얼마나 자주 수행할 것인지를 지정한다.  

```json
PUT my_index/_settings
{
    "index.refresh_interval": "1s"
}
```

`-1`로 지정하면 주기적 refresh를 수행하지 않는다.  

```json
{
  "my_index": {
    "settings": {
      "index": {
        "routing": {
          "allocation": {
            "include": {
              "_tier_preference": "data_content"
            }
          }
        },
        "number_of_shards": "1",
        "provided_name": "my_index",
        "creation_date": "1701589928336",
        "number_of_replicas": "1",
        "uuid": "D04h6TQ4TneP3YMujx8rHA",
        "version": {
          "created": "8040299"
        }
      }
    }
  }
}
```

만약 위의 예제처럼 값이 명시적으로 설정되어 있지 않으면 매 1초마다 refresh를 수행하며, 마지막으로 검색 쿼리가 들어온 시각을 확인한다.  
30초 이상 검색 쿼리가 들어오지 않는 것을 확인하면 다음 첫 검색 쿼리가 들어올때 까지 refresh를 수행하지 않는다.  
이 대기시간도 `index.search.idle.after`로 설정할 수 있다.  

# 매핑과 필드 타입

매핑은 문서가 인덱스에 어떻게 색인되고 저장되는지 정의하는 부분이며 각 필드를 어떤 방식으로 분석하고 색인할지, 어떤 타입으로 저장할지 등을 세부적으로 지정할 수 있다.  
매핑 정보를 가지고 있지 않던 새로운 필드가 들어오면 엘라스틱서치는 자동으로 타입을 지정해서 매핑 정보를 생성한다.  

```json
PUT my_index2/_doc/1
{
  "title": "hello world",
  "views": 1234,
  "public": true,
  "point": 4.5,
  "created": "2023-12-05T21:48:09.234Z"
}

GET my_index2
{
  "my_index2": {
    "aliases": {},
    "mappings": {
      "properties": {
        "created": {
          "type": "date"
        },
        "point": {
          "type": "float"
        },
        "public": {
          "type": "boolean"
        },
        "title": {
          "type": "text",
          "fields": {
            "keyword": {
              "type": "keyword",
              "ignore_above": 256
            }
          }
        },
        "views": {
          "type": "long"
        }
      }
    },
    "settings": {
      "index": {
        "routing": {
          "allocation": {
            "include": {
              "_tier_preference": "data_content"
            }
          }
        },
        "number_of_shards": "1",
        "provided_name": "my_index2",
        "creation_date": "1701780498209",
        "number_of_replicas": "1",
        "uuid": "Ph2sRK1oR6mhU1HzAhrbRQ",
        "version": {
          "created": "8040299"
        }
      }
    }
  }
}
```

중요한 것은 필드 타입을 포함한 매핑 설정 내 대부분의 내용은 **한 번 지정되면 변경이 불가능 하다는 점이다.**  
위와 같은 이유로 서비스 운영 환경에서 대용량의 데이터를 처리해야 할 때는 기본적으로 명시적으로 매핑을 지정해서 인덱스를 운영해야 한다.  

# 필드 타입

필드의 값이 어떤 형태로 저장될지를 저장한다.  

- **심플 타입** : text, keyword, date, long, double, boolean, ip 등
  - 숫자 타입
  - date 타입

## 배열

별도로 배열을 표현하는 타입은 없다.  
ES는 색인 과정에서 **데이터가 단일 데이터인지 배열 데이터인지에 상관없이 각 값마다 하나의 독립적인 역색인을 구성하기 때문이다.**  

```json
PUT array_test/_doc/1
{
  "longField": 309,
  "keywordField": ["hello", "world"]
}

PUT array_test/_doc/2 
{
  "longField": [309, 1101],
  "keywordField": "hello"
}

{
  "mappings": {
    "properties": {
      "keywordField": {
        "type": "text",
        "fields": {
          "keyword": {
            "type": "keyword",
            "ignore_above": 256
          }
        }
      },
      "longField": {
        "type": "long"
      }
    }
  }
}
```

아래와 같은 색인은 실패한다.

```json
PUT array_test/_doc/3
{
  "longField": [309, "hello"]
}
```
  

## 계층 구조를 지원하는 타입

계층 구조의 데이터를 담는 타입으로는 **object** 와 **nested** 가 있다.  
이 둘은 유사하나 배열을 처리할 때의 동작이 다르다.  
  
### object
  
JSON 문서는 필드의 하위에 다른 필드를 여럿 포함하는 객체를 담을 수 있다.

```json
PUT object_test/_doc/1
{
  "price": 2770.1,
  "spec": {
    "cores": 12,
    "memory": 128,
    "stroage": 8000
  }
}

GET object_test
{
  "mappings": {
    "properties": {
      "price": {
        "type": "float"
      },
      "spec": {
        "properties": {
          "cores": {
            "type": "long"
          },
          "memory": {
            "type": "long"
          },
          "stroage": {
            "type": "long"
          }
        }
      }
    }
  }
}
```

object 타입이 기본값이기 때문에 `spec` 필드의 타입을 명시적으로 object라고 표현하지 않는다.  
이 문서는 내부적으로 아래와 같이 평탄화된 **키-값 쌍으로 색인된다.**  

```json
{
  "price": 2770.1,
  "spec.cores": 12,
  "spec.memory": 128,
  "spec.stroage": 8000
}
```
  
object 타입으로 배열을 넣으면 어떻게 될까?

```json
PUT object_test/_doc/3
{
  "price": 2770.1,
  "spec": [
    {
      "cores": 1,
      "memory": 128,
      "stroage": 8000
    },
    {
      "cores": 2,
      "memory": 128,
      "stroage": 8000
    },
    {
      "cores": 3,
      "memory": 128,
      "stroage": 8000
    }
  ]
}
```

```json
GET object_test/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "term": {
            "spec.cores": 1
          }
        },
        {
          "term": {
            "spec.memory": 128
          }
        }
      ]
    }
  }
}
```

위의 bool 쿼리의 must로 작성하였기 때문에 cores가 1개고 memory가 128인 문서를 찾는다.  
1건이 조회될 것 같지만 결과는 3건 모두 조회된다.  

```json
{
  "took": 14,
  "timed_out": false,
  "_shards": {
    "total": 1,
    "successful": 1,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 2,
    "hits": [
      {
        "_index": "object_test",
        "_id": "3",
        "_score": 2,
        "_source": {
          "price": 2770.1,
          "spec": [
            {
              "cores": 1,
              "memory": 128,
              "stroage": 8000
            },
            {
              "cores": 2,
              "memory": 128,
              "stroage": 8000
            },
            {
              "cores": 3,
              "memory": 128,
              "stroage": 8000
            }
          ]
        }
      }
    ]
  }
}
```

object 타입의 데이터가 어떻게 평탄화되는지를 떠올려보면 이해할 수 있다.

```json
{
  "spec.cores": [1, 2, 3],
  "spec.memory": [128],
  "spec.storage": [8000]
}
```

그렇기 때문에 두 개의 term 조건만 참이 된다면 모두 포함되는 것이다.  
만약 두 개의 term 중 하나라도 포함되지 않으면 모두 조회되지 않는다.  
예를 들어 cores가 1,2,3에 포함되지 않거나 memory가 128이 아니라면 말이다.  

### nested

nested 타입은 object 타입과는 다르게 배열 내 각 객체를 독립적으로 취급한다.  
nested 타입은 직접 명시해줘야 한다.

```json
PUT nested_test
{
  "mappings": {
    "properties": {
      "spec": {
        "type": "nested",
        "properties": {
          "cores": {
            "type": "long"
          },
          "memory": {
            "type": "long"
          },
          "storage": {
            "type": "long"
          }
        }
      }
    }
  }
}

PUT nested_test/_doc/2
{
  "spec": [
    {
      "cores": 12,
      "memory": 128,
      "stroage": 8000
    },
    {
      "cores": 6,
      "memory": 64,
      "stroage": 8000
    },
    {
      "cores": 6,
      "memory": 32,
      "stroage": 8000
    }
  ]
}

GET nested_test/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "term": {
            "spec.cores": 12
          }
        },
        {
          "term": {
            "spec.memory": 128
          }
        }
      ]
    }
  }
}
```

위의 GET 질의를 통해 한 건을 기대하지만 실제로는 아무것도 검색되지 않는다.  
**nested 타입은 객체 배열의 각 객체를 내부적으로 별도의 루씬 문서로 분리해 저장한다.**  
배열의 원소가 100개라면 부모 문서까지 해서 101개의 문서가 내부적으로 생성된다.  
  
nested의 이런 동작 방식은 엘라스틱서치 내에서 굉장히 특수하기 때문에 `nested` 쿼리라는 전용 쿼리를 이용해서 검색해야 한다.  

```json
GET nested_test/_search
{
  "query": {
    "nested": {
      "path": "spec",
      "query": {
        "bool": {
          "must": [
            {
              "term": { "spec.cores": 6 }
            },
            {
              "term": { "spec.memory": 64 }
            }
          ]
        }
      }
    }
  }
}
```

위의 질의로 3건 모두 조회할 수 있다.  
  
내부적으로 문서를 분리해서 저장하기 때문에 성능 문제가 있을 수 있다. 따라서 nested 타입의 무분별한 사용을 막기 위해 인덱스 설정으로 두 가지 제한을 걸어 놓았다.  

## 문자열 필드 타입

`text`로 지정된 필드 값은 애널라이저가 적용된 후 색인된다.  
**들어온 문자열 값 그대로를 가지고 역색인을 구성하는 것이 아니라 값을 분석하여 여러 토큰으로 쪼갠다.**  
이렇게 쪼개진 토큰으로 역색인을 구성한다.  
쪼개진 토큰에 지정한 필터를 적용하는 등의 후처리 작업 후 최종적으로 역색인에 들어가는 형태를 **텀 (term)** 이라고 한다.  
  
반면에 `keyword`로 지정된 필드에 들어온 문자열 값은 여러 토큰으로 쪼개지 않고 역색인을 구성한다.  
**애널라이저로 분석하는 대신 노멀라이저를 사용한다.**  
노멀라이저는 간단한 전처리만을 거친 뒤 커다란 단일 텀으로 역색인을 구성한다.  

```json
 PUT mapping_test
{
  "mappings": {
    "properties": {
      "keywordString": {
         "type": "keyword"
      },
      "textString": {
        "type": "text"
      }
    }
  }
}

PUT mapping_test/_doc/1
{
  "keywordString": "Hello, World!",
  "textString": "Hello, World!"
}

```

```json
GET mapping_test/_search
{
  "query": {
    "match": {
      "textString": "hello"
    }
  }
}

{
    "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 0.2876821,
    "hits": [
      {
        "_index": "mapping_test",
        "_id": "1",
        "_score": 0.2876821,
        "_source": {
          "keywordString": "Hello, World!",
          "textString": "Hello, World!"
        }
      }
    ]
  }
}
```

`textString`은 한 건이 조회되었지만 아래의 `keywordString`은 조회되지 않는다.

```json
GET mapping_test/_search
{
  "query": {
    "match": {
      "keywordString": "hello"
    }
  }
}

{
    "hits": {
    "total": {
      "value": 0,
      "relation": "eq"
    },
    "max_score": null,
    "hits": []
  }
}
```

keyword는 애널라이저를 통해 문자열을 쪼개지 않고 노멀라이저로 단일 토큰을 구성하기 때문에 검색되지 않는 것이다.  

> **text**
> - 전문 검색에 적합
> - **fielddata** 라는 캐시를 사용
> 
> **keyword**
> - 일치 검색에 적합
> - 정렬과 집계, 스크립트 작업의 대상이 될 필드에 적합
> - **doc_values** 라는 캐시를 사용

## 문자열 캐시 타입

ES의 검색은 역색인을 기반으로 한 색인을 이용한다. 텀을 보고 역색인에서 문서를 찾는 방식이다.  
그러나 **정렬, 집계, 스크립트 작업 시에는 접근법이 다르다.**  
문서를 보고 필드내의 텀을 찾는다.  
  
keyword 타입이 기본적으로 사용하는 **doc_values** 캐시는 **디스크를 기반으로 한 자료 구조로 파일 시스템 캐시를 통해 효율적으로 정렬, 집계, 스크립트 작업을 수행할 수 있게 설계됐다.**  
- ES의 `text`와 `annotated_text` 타입을 제외한 거의 모든 필드 타입이 이 doc_values를 지원한다.
  
대부분의 필드 타입은 doc_values를 사용할 수 있지만 text 타입은 파일 시스템 기반의 캐시인 doc_values를 사용할 수 없다.  
text 필드는 **fielddata** 캐시를 이용하며 정렬이나 집계 등의 작업 시에는 역색인 전체를 읽어들여 힙 메모리에 올린다.  
하지만 메모리에 역색인 내용 전체를 올리기 때문에 OOM에 유의해야 한다.  
기본적으로 비활성화 되어있고 신중하게 사용해야한다.  
  
# _source

문서 색인 시점에 ES에 전달된 원본 JSON 문서를 저장하는 **메타데이터 필드** 다.  
문서 조회 API나 검색 API가 클라이언트에게 반환할 문서를 확정하고 나면 이 필드에 저장된 값을 읽어 클라이언트에게 반환한다.  
- _source 필드 자체는 역색인을 생성하지 않기 때문에 검색 대상이 되지 않는다.

`reindex` 작업도 _source의 원본 JSON 데이터를 읽어 재색인 작업을 수행한다.  

# index

index 속성은 해당 필드의 역색인을 만들 것인지를 지정한다.  
기본값은 `true`이며, `false`로 설정하면 해당 필드는 역색인이 없기 때문에 일반적인 검색 대상이 되지 않는다.  
  
검색 대상이 될 가능성이 없거나 혹은 검색 대상이 되더라도 소규모의 검색만 필요할 경우는 필드의 index 값을 false로 지정해 성능상 이득을 볼 수 있다.

```json
PUT mapping_test/_mapping
{
  "properties": {
    "notSearchableText": {
      "type": "text",
      "index": false
    },
    "docValuesSearchableText": {
      "type": "keyword",
      "index": false
    }
  }
}

PUT mapping_test/_doc/4
{
  "textString": "Hello, World!",
  "notSearchableText": "Hello, World!",
  "docValueSearchableText": "hello"
}

GET mapping_test/_search
{
  "query": {
    "match": {
      "notSearchableText": "hello"
    }
  }
}
```

위와 같이 검색을 하면 예외가 발생한다.


```json
{
  "error": {
    "root_cause": [
      {
        "type": "query_shard_exception",
        "reason": "failed to create query: Cannot search on field [notSearchableText] since it is not indexed.",
        "index_uuid": "phWKcQZRSjeddMKh-TaKZg",
        "index": "mapping_test"
      }
    ],
    "type": "search_phase_execution_exception",
    "reason": "all shards failed",
    "phase": "query",
    "grouped": true,
    "failed_shards": [
      {
        "shard": 0,
        "index": "mapping_test",
        "node": "a-03VgoCRIKA5l8huuG_zA",
        "reason": {
          "type": "query_shard_exception",
          "reason": "failed to create query: Cannot search on field [notSearchableText] since it is not indexed.",
          "index_uuid": "phWKcQZRSjeddMKh-TaKZg",
          "index": "mapping_test",
          "caused_by": {
            "type": "illegal_argument_exception",
            "reason": "Cannot search on field [notSearchableText] since it is not indexed."
          }
        }
      }
    ]
  },
  "status": 400
}
```

필드를 `textString`으로 변경하면 검색이 정상적으로 되고 `notSearchableText`도 포함되어 있다.

```json
{
  "hits": [
      {
        "_index": "mapping_test",
        "_id": "1",
        "_score": 0.18232156,
        "_source": {
          "keywordString": "Hello, World!",
          "textString": "Hello, World!"
        }
      },
      {
        "_index": "mapping_test",
        "_id": "4",
        "_score": 0.18232156,
        "_source": {
          "textString": "Hello, World!",
          "notSearchableText": "Hello, World!",
          "docValueSearchableText": "hello"
        }
      }
    ]
  }
}
```

그리고 index 속성은 false이지만 keyword 타입은 **doc_values** 를 사용하기 때문에 역색인이 없더라도 doc_values 검색을 수행한 것이다.  

```json
GET mapping_test/_search
{
  "query": {
    "match": {
      "docValueSearchableText": "hello"
    }
  }
}

{
  "hits": [
    {
      "_index": "mapping_test",
      "_id": "4",
      "_score": 0.2876821,
      "_source": {
        "textString": "Hello, World!",
        "notSearchableText": "Hello, World!",
        "docValueSearchableText": "hello"
      }
    }
  ]
}
```

# 인덱스 운영 전략

1. **매핑이 동적으로 생성되도록 하기 보다는 최대한 명시적으로 매핑을 지정하라**
2. **라우팅을 활용하라**
3. **시계열 데이터를 색인한다면 인덱스 이름에도 시간값을 넣는 방법을 고려하라**
   - 예를 들어 `api-history-20240101`이나 `access-log-202401`와 같이 말이다.
   - 이런 방법을 선택하면 오래된 데이터를 백업하고 삭제하는 것이 편하다.
4. **alias**
   - 이미 존재하는 인덱스를 다른 이름으로 가리키도록 하는 기능이다.
   - 한 alias가 하나 이상의 인덱스를 가리키도록 지정할 수도 있다.
   - 다만 여러 인덱스를 가리키는 alias는 단건 문서 조회 작업의 대상이 될 수 없다.
   - alias를 등록할 때 `is_write_index` 속성을 설정해서 쓰기 작업을하는 인덱스를 지정할 수 있다.
5. **롤오버**
   - `is_write_index` 속성을 통해 RW를 분리하여 운영중에 쓰기 인덱스 내 샤드의 크기가 너무 커지면 새로운 인덱스를 생성해서 같은 alias에 묶은 뒤 `is_write_true`를 새 인덱스로 옮기는 방식으로 운영한다.
   - 롤오버는 이러한 작업을 한 번에 묶어서 수행하는 기능이다.
   - `POST [롤오버 대상]/_rollover`
   - 만약 `test-index-00001`의 인덱스를 롤오버하면 `test-index-00002`가 새로 생기며 쓰기 속성이 활성화된다.
   - **데이터스트림과 묶어서 사용하기도 좋다.**
6. **데이터 스트림**
   - 내부적으로 여러 개의 인덱스로 구성되어 있으며, 검색을 수행할 때는 해당 데이터 스트림에 포함된 모든 인덱스를 대상으로 검색을 수행하고, 문서를 추가 색인할 때는 가장 최근에 생성된 단일 인덱스에 새 문서가 들어간다.
   - 즉, 데이터 스트림은 마치 여러 인덱스를 묶고 `is_write_true` 인덱스를 하나 둔 alias와 유사하게 동작한다.

## 데이터 스트림

alias와의 차이점은 아래와 같다.

1. 데이터 스트림을 구성하는 인덱스는 뒷받침 인덱스라고 부르며 모두 hidden 속성이다
2. 이 뒷받침 인덱스는 이름 패턴이 고정이고, 롤오버 시 명시적인 새 인덱스 이름 지정이 불가능하다.
3. 패턴은 `.ds-<데이터 스트림 이름>-<yyyy.MM.dd>-<세대 수>`다. 세 대수는 6자리 자연수다.
4. 반드시 인덱스 탬플릿과 연계해서 생성해야 한다.
5. 문서 추가는 가능하지만 업데이트 작업은 불가능하다.
   - 데이터 스트림을 대상으로 문서 업데이트나 삭제 작업을 수행하려면 `update_by_query`나 `delete_by_query`를 사용해야 한다.
6. 반드시 `@timestamp` 필드가 포함된 문서만을 취급한다.

데이터 스트림을 직접 만들어보자
먼저 **ILM (Index Lifecycle Management, 인덱스 생명 주기 관리)** 정책을 생성한다.  

```json
PUT _ilm/policy/test-ilm-policy
{
  "policy": {
    "phases": {
      "hot": {
        "min_age": "0ms",
        "actions": {
          "rollover": {
            "max_age": "1d",
            "max_primary_shard_size": "4gb"
          }
        }
      }
    },
    "delete": {
      "min_age": "15d",
      "actions": {
        "delete": { }
      }
    }
  }
}
```

하루가 지나거나 4gb가 넘으면 자동으로 rollover되며 15일이 지난 뒷받침 인덱스는 자동 삭제한다.  
데이터 스트림은 **반드시 인덱스 템플릿과 연계되어야 한다.**  
컴포넌트 템플릿 두 개를 생성하자

```json
PUT _component_template/test-mappings
{
  "template": {
    "mappings": {
      "properties": {
        "@timestamp": {
          "type": "date"
        }
      }
    }
  }
}

PUT _component_template/test-settings
{
  "template": {
    "settings": {
      "index.lifecycle.name": "test-ilm-policy",
      "number_of_shards": 2,
      "number_of_replicas": 1
    }
  }
}
```

다음으로 두 컴포넌트 템플릿을 포함한 인덱스 템플릿을 생성하여 데이터 스트림 전용 템플릿을 생성하자.

```json
PUT _index_template/test-data-stream-template
{
  "index_patterns": ["my-data-stream-*"],
  "data_stream": {},
  "composed_of": ["test-mappings", "test-settings"]
}
```

이제 데이터 스트림을 생성하고 색인해보자

```json
PUT _data_stream/my-data-stream-first

PUT my-data-stream-first/_create/1
{
  "hello": "world",
  "@timestamp": "2024-01-01T23:00:00.000Z"
}

# res
{
  "_index": ".ds-my-data-stream-first-2024.01.01-000001",
  "_id": "1",
  "_version": 1,
  "result": "created",
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "_seq_no": 0,
  "_primary_term": 1
}

GET my-data-stream-first/_search

# res
{
  "took": 906,
  "timed_out": false,
  "_shards": {
    "total": 2,
    "successful": 2,
    "skipped": 0,
    "failed": 0
  },
  "hits": {
    "total": {
      "value": 1,
      "relation": "eq"
    },
    "max_score": 1,
    "hits": [
      {
        "_index": ".ds-my-data-stream-first-2024.01.01-000001",
        "_id": "1",
        "_score": 1,
        "_source": {
          "hello": "world",
          "@timestamp": "2024-01-01T23:00:00.000Z"
        }
      }
    ]
  }
}
```

## reindex

원본 인덱스 내 문서의 `_source`를 읽어서 대상 인덱스에 새로 색인하는 작업이다.  

```json
POST _reindex
{
  "source": {
    "index": "source_index",
    "query": {
      ...
    }
  },
  "dest": {
    "index": "target_index"
  },
  "conflicts": "abort"
}
```

작업 도중 버전 충돌이 일어나면 `abort`는 해당 부분까지만 진행되고 취소하며, `proceed`는 계속 진행한다.  
`source`의 `query`로 검색 쿼리를 지정해서 대상을 제한할 수 있다.  
  
**reindex 작업은 작업의 크기가 큰 경우가 많기 때문에 task에 등록하고 비동기적 실행을 할 수 있다.**  
`wait_for_completion=false`를 지정해서 스토틀링을 적용하거나, `slices`를 지정해 슬라이싱을 적용하는 부분도 `update_by_query`, `delete_by_query`와 동일하다.  

## shrink로 샤드 개수 줄이기

`shrink`는 샤드의 개수를 줄이면서 인덱스를 새로 생성하는 작업이다.  
원본이 될 현재 인덱스 이름과 새로 생성할 인덱스의 이름을 지정하고 요청 본문에 샤드 개수를 지정한다.  
  
reindex는 기본적으로 새 인덱스에 문서를 다시 새로 색인하는 과정이여서 새 인덱스를 생성할 때 설정이나 매핑을 원하는 대로 바꿔서 생성한 뒤 새 인덱스 설정에 맞춰 색인이 수행된다.  
shrink는 기존 인덱스의 세그먼트를 새 인덱스로 하드링크한다. 샤드 개수를 제외한 인덱스 설정과 매핑이 유지된다.  
  
## split으로 샤드 개수 늘리기

`split`은 샤드의 개수를 늘리면서 인덱스를 새로 생성하는 작업이다.  
split 역시 shrink와 마찬가지로 새 인덱스 생성 후에 원본 인덱스의 세그먼트를 하드 링크하는 방식으로 작업이 진행된다.  

## 다중 필드

실무에서는 서비스가 이미 운영 중이고 매핑도 확정되었는데 특정 필드를 기존과 다른 방법으로 색인해야 하는 상황이 생긴다.  
예를 들면, `keyword` 타입으로 색인 중이던 데이터를 애널라이저를 적용한 `text` 타입으로 색인해야 할 수 있다.  
이런 상황에서 **다중 필드** 를 사용할 수 있다.  
  
다중 필드는 필드 하나에 여러 이름을 붙인 뒤 각각 다른 매핑을 적용해서 사용할 수 있게 해준다.  

```json
PUT multi-fields-test
{
  "mappings": {
    "properties": {
      "my_string_field": {
        "type": "keyword"
      }
    }
  }
}

PUT multi-fields-test/_mapping
{
  "properties": {
    "my_string_field": {
      "type": "keyword",
      "fields": {
        "text_standard": {
          "type": "text",
          "analyzer": "standard"
        },
        "text_whitespace": {
          "type": "text",
          "analyzer": "whitespace"
        }
      }
    }
  }
}
```

`fields`라는 속성을 지정한 뒤 그 밑에 `text_standard`, `text_whitespace`라는 필드 이름을 추가로 지정했다.  
이렇게 다중 필드를 지정하면 이후 이 필드는 `my_string_field`로 접근할 때는 **keyword 타입** 으로,  
`my_string_field.text_standard`로 접근할 때는 **standard 애널라이저를 적용한 text 타입으로 동작** 한다.  
  
인덱스에 한 번 지정된 매핑은 변경할 수 없지만 새 매핑을 추가하는 것은 가능하기에 운영 도중 다중 필드를 추가할 수 있다.  
하지만 매핑이 적용된 이후 들어오는 데이터부터 적용되며 기존 데이터는 다시 색인을 해야 추가된 다중 필드가 적용된다.  

## 타입이 계속 변경되는 데이터

필드의 타입이 매번 변경되어야 하는 요구사항이 있을 수 있다.  
이런 경우에는 ES와 어울리지 않긴 하지만 타입을 `object`로 지정한뒤 `enabled: false`를 지정하는 방법을 사용할 수 있다.  
하지만 해당 필드 타입에 대한 검색은 포기해야 한다.  

## 루씬 텀 길이 제약

`string` 필드에 매우 긴 데이터가 들어오면 루씬 텀 길이 제약에 걸려 문서의 색인이 거부되는 경우가 생길 수 있다.  
특히 `keyword` 타입은 필드 내용을 통째로 하나의 텀으로 만들기 때문에 이런 상황이 발생하기 쉽다.  
**루씬의 최대 텀 길이는 32766 바이트이다.**  
  
```json
PUT [인덱스 이름]
{
  "mappings": {
    "properties": {
      "my_string_field": {
        "type": "keyword",
        "ignore_above": 1000
      }
    }
  }
}
```

만약 keyword 타입을 사용하고 이런 긴 데이터를 색인에 넣어둬야 할 특별한 이유가 없다면 처음부터 매핑에 `ignore_above`를 지정하는 것을 고려할 수 있다.  
이 지정한 수치보다 긴 텀을 역색인에 넣지 않도록 해주는 속성이다.  
해당 값은 바이트 단위가 아니라 문자 단위다.  
text 타입은 지정할 수 없으며 루씬 최대 텀 길이에 도달했다면 애널라이저를 바꾸거나 enabled: flase 지정을 고려해야 한다.  
