롱 폴링에서 전송 순서를 보장하는 방법으로 한 번에 한 요청만 대기할 수 있게 하는 방법이 있다.  
클라이언트가 마지막 요청에 대한 응답을 받기 전에는 다른 요청을 전송하지 않으므로 이전 메시지가 수신되면 안전하게 다음 메시지를 전송할 수 있다.  
  
이와 비슷하게 서버 측에서도 클라이언트가 이전 응답을 수신하기 전에는 대기할 요청이 새로 들어오지 않는다.  
따라서 요청 사이에 버퍼의 내용을 모두 전송해도 안전하다.  
  
그런데 이러한 단일 요청 기법을 이용하면 클라이언트와 서버가 모두 메시지를 버퍼링하는 데 상당한 시간을 소비한다는 한 가지 큰 단점이 있다.  
예를 들어 클라이언트에 전송할 새로운 데이터가 있지만,이미 대기 중인 요청이 있는 경우 서버가 응답할 때까지 기다려야 새로운 요청을 전송할 수 있다.  
따라서 서버에 데이터가 없을 때는 시간이 오래 걸릴 수 있다.  
  
동시에 전송되는 요청의 수를 늘리면 솔루션의 성능을 개선할 수 있다.  
단일 요청 패턴을 최대 두 요청 패턴으로 바꾸면 된다.  
이 알고리즘은 두 부분으로 이뤄진다  

1. 클라이언트는 현재 처리 중인 요청이 두 개가 아닌 경우에만 새로운 데이터를 전송한다.
2. 서버는 클라이언트로부터 요청을 수신할 때마다 클라이언트에서 받은 열린 요청이 이미 있지 않으면 데이터가 없더라도 즉시 첫 번째 요청에 응답한다

이 방법으로 단일 요청 패턴에 비해 상당히 중요한 개선점을 제공할 수 있다.  
즉,클라이언트와 서버의 버퍼 시간이 단일 네트워크 왕복 시간과 연결된다.  
물론 이러한 성능 향상을 얻으려면 코드 복잡성이 상응하는 수준으로 상승하는 것을 감수해야 한다.  
  
롱 폴링 알고리즘으로는 더 이상 메시지 전송 순서를 보장할 수 없지만 TCP에서 얻은 몇 가지 아이디어를 활용해 순서를 보장할 수 있다.
클라이언트가 전송하는 각 요청에 점차 증가하는 일련번호를 넣고, 해당 페이로드 내의 메시지 수에 대한 메타데이터를 넣는다.  
메시지가 여러 요청에 걸쳐 전송되는 경우 이 페이로드에 들어 있는 메시지의 부분을 메타데이터에 넣는다.  
  
서버는 들어오는 메시지 세그먼트의 링 버퍼를 유지하면서 이전의 완성되지 않은 메시지가 없으면 메시지가 완성되는 즉시 이를 처리한다.
  
다운스트림은 롱 폴링 전송이 HTTP GET 요청에 응답하며 페이로드 크기에 대한 제약을 동일하게 받지 않으므로 좀 더 수월하며,일련번호를 넣고 각 응답에 일련번호를 증가시킨다.  
클라이언트는 주어진 일련번호까지 모든 응답을 수신한 경우 리스트에 있는 메시지를 모두 처리할 수 있으며 그렇지 않으면 대기 중인 응답을 수신할 때까지 리스트를 버퍼링한다.  
  
## 14.3.5 네티의 탁월한 동시 연결 지원 능력

앞에서도 언급했듯이 네티를 이용하면 JVM 상에서 비동기 입출력을 손쉽게 지원할 수 있다.
네티는 JVM에서 실행되며 리눅스 상의 JVM은 궁극적으로 리눅스 epoll 기능을 이용해 소켓 파일 설명자의 관심사를 관리하므로 네티는 리눅스 프로세스당 TCP 연결 100만 개에 가까운 많은 수의 열린 소켓을 이용할 수 있게 하는 방법으로 빠른 모바일 성장세를 간단하게 지원할 수 있다.  
이러한 확장성을 바탕으로 서비스 공급자는 비용을 절감하고 단일 물리 서버상의 단일 프로세스로 많은 수의 장치 연결을 허용할 수 있다.  
  
> 여기서 물리 서버라고 지정한 데 주의하자. 가상화로 여러 혜택을 얻을 수 있지만 주요 클라우드 공급업체에서도 단일 가상 호스트에 대한 동시 연결이 200.000~300.000개 정도로 제한되는 경우가 많다. 
> 그 이상의 동시 연결을 지원해야 한다면 베어메탈 서버를 이용하고 NIC（네트워크 인터페이스 카드） 벤더에도 주의를 기울여야 한다.


> 모든 비동기 스리프트 클라이언트가 파이프라인을 통해 요청을 전송하는 경우 이러한 요청에 대한 응답을 받는 순서에 관계없이 처리할 수 있다면 좋겠지만 최신 클라이언트와 달리 기존 비동기 스리프트 클라이언트는 여러 요청을 전송할 수는 있지만 응답을 순서대로 받아야 올바르게 처리할 수 있다.  
> 이러한 유형의 문제는 네티4의 EventExecutor 또는 네티 3.x의 OrderedMemoryAwareThreadPoolExcecutor를 이용해 모든 메시지를 동일한 실행자 스레드에서 실행하도록 강제하지 않고도 한 연결에서 들어오는 메시지를 순차적으로 처리하는 방법으로 해결할 수 있다